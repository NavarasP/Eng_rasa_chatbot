{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar Errors: [Match({'ruleId': 'UPPERCASE_SENTENCE_START', 'message': 'This sentence does not start with an uppercase letter.', 'replacements': ['Or'], 'offsetInContext': 43, 'context': '...hrases for details on potential errors. or use this text too see an few of of the ...', 'offset': 168, 'errorLength': 2, 'category': 'CASING', 'ruleIssueType': 'typographical', 'sentence': 'or use this text too see an few of of the problems that LanguageTool can detecd.'}), Match({'ruleId': 'TOO_TO', 'message': 'Did you mean “to see”?', 'replacements': ['to see'], 'offsetInContext': 43, 'context': '...s on potential errors. or use this text too see an few of of the problems that Language...', 'offset': 185, 'errorLength': 7, 'category': 'CONFUSED_WORDS', 'ruleIssueType': 'misspelling', 'sentence': 'or use this text too see an few of of the problems that LanguageTool can detecd.'}), Match({'ruleId': 'EN_A_VS_AN', 'message': 'Use “a” instead of ‘an’ if the following word doesn’t start with a vowel sound, e.g. ‘a sentence’, ‘a university’.', 'replacements': ['a'], 'offsetInContext': 43, 'context': '...ential errors. or use this text too see an few of of the problems that LanguageToo...', 'offset': 193, 'errorLength': 2, 'category': 'MISC', 'ruleIssueType': 'misspelling', 'sentence': 'or use this text too see an few of of the problems that LanguageTool can detecd.'}), Match({'ruleId': 'ENGLISH_WORD_REPEAT_RULE', 'message': 'Possible typo: you repeated a word', 'replacements': ['of'], 'offsetInContext': 43, 'context': '...errors. or use this text too see an few of of the problems that LanguageTool can dete...', 'offset': 200, 'errorLength': 5, 'category': 'MISC', 'ruleIssueType': 'duplication', 'sentence': 'or use this text too see an few of of the problems that LanguageTool can detecd.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['detect'], 'offsetInContext': 43, 'context': '...f of the problems that LanguageTool can detecd. What do you thinks of grammar checkers...', 'offset': 241, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'or use this text too see an few of of the problems that LanguageTool can detecd.'}), Match({'ruleId': 'DO_VBZ', 'message': 'After the auxiliary verb ‘do’, use the base form of the main verb. Did you mean “think”?', 'replacements': ['think'], 'offsetInContext': 43, 'context': '...at LanguageTool can detecd. What do you thinks of grammar checkers? Please not that th...', 'offset': 261, 'errorLength': 6, 'category': 'GRAMMAR', 'ruleIssueType': 'grammar', 'sentence': 'What do you thinks of grammar checkers?'}), Match({'ruleId': 'PLEASE_NOT_THAT', 'message': 'Did you mean “note”?', 'replacements': ['note'], 'offsetInContext': 43, 'context': '... you thinks of grammar checkers? Please not that they are not perfect. Style issues...', 'offset': 296, 'errorLength': 3, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Please not that they are not perfect.'}), Match({'ruleId': 'PM_IN_THE_EVENING', 'message': 'This is redundant. Consider using “P.M.”', 'replacements': ['P.M.'], 'offsetInContext': 43, 'context': '... Style issues get a blue marker: It’s 5 P.M. in the afternoon. The weather was nice on Thursday, 27 J...', 'offset': 366, 'errorLength': 21, 'category': 'REDUNDANCY', 'ruleIssueType': 'style', 'sentence': \"Style issues get a blue marker: It's 5 P.M. in the afternoon.\"}), Match({'ruleId': 'DATE_WEEKDAY', 'message': 'The date 27 June 2017 is not a Thursday, but a Tuesday.', 'replacements': [], 'offsetInContext': 43, 'context': '... the afternoon. The weather was nice on Thursday, 27 June 2017', 'offset': 413, 'errorLength': 22, 'category': 'SEMANTICS', 'ruleIssueType': 'inconsistency', 'sentence': 'The weather was nice on Thursday, 27 June 2017'})]\n",
      "Error: UPPERCASE_SENTENCE_START, Message: This sentence does not start with an uppercase letter., Suggestion: ['Or']\n",
      "Error: TOO_TO, Message: Did you mean “to see”?, Suggestion: ['to see']\n",
      "Error: EN_A_VS_AN, Message: Use “a” instead of ‘an’ if the following word doesn’t start with a vowel sound, e.g. ‘a sentence’, ‘a university’., Suggestion: ['a']\n",
      "Error: ENGLISH_WORD_REPEAT_RULE, Message: Possible typo: you repeated a word, Suggestion: ['of']\n",
      "Error: MORFOLOGIK_RULE_EN_US, Message: Possible spelling mistake found., Suggestion: ['detect']\n",
      "Error: DO_VBZ, Message: After the auxiliary verb ‘do’, use the base form of the main verb. Did you mean “think”?, Suggestion: ['think']\n",
      "Error: PLEASE_NOT_THAT, Message: Did you mean “note”?, Suggestion: ['note']\n",
      "Error: PM_IN_THE_EVENING, Message: This is redundant. Consider using “P.M.”, Suggestion: ['P.M.']\n",
      "Error: DATE_WEEKDAY, Message: The date 27 June 2017 is not a Thursday, but a Tuesday., Suggestion: []\n"
     ]
    }
   ],
   "source": [
    "from language_tool_python import LanguageTool\n",
    "\n",
    "paragraph = \"LanguageTool offers spell and grammar checking. Just paste your text here and click the ‘Check Text’ button. Click the colored phrases for details on potential errors. or use this text too see an few of of the problems that LanguageTool can detecd. What do you thinks of grammar checkers? Please not that they are not perfect. Style issues get a blue marker: It’s 5 P.M. in the afternoon. The weather was nice on Thursday, 27 June 2017\"\n",
    "\n",
    "def check_grammar(para):\n",
    "    tool = LanguageTool('en-US')\n",
    "    matches = tool.check(para)\n",
    "    return matches\n",
    "\n",
    "grammar_errors = check_grammar(paragraph)\n",
    "print(\"Grammar Errors:\",grammar_errors)\n",
    "\n",
    "for error in grammar_errors:\n",
    "    print(f\"Error: {error.ruleId}, Message: {error.message}, Suggestion: {error.replacements}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph:\n",
      "He do not likes to go outside. Her writing skill are good, but she could of improved it. The weather is to cold today.\n",
      "\n",
      "Tokenized Sentences:\n",
      "['He do not likes to go outside.', 'Her writing skill are good, but she could of improved it.', 'The weather is to cold today.']\n",
      "\n",
      "Part-of-Speech Tags:\n",
      "[[('He', 'PRP'), ('do', 'VB'), ('not', 'RB'), ('likes', 'VB'), ('to', 'TO'), ('go', 'VB'), ('outside', 'RB'), ('.', '.')], [('Her', 'PRP$'), ('writing', 'NN'), ('skill', 'NN'), ('are', 'VBP'), ('good', 'JJ'), (',', ','), ('but', 'CC'), ('she', 'PRP'), ('could', 'MD'), ('of', 'IN'), ('improved', 'VBN'), ('it', 'PRP'), ('.', '.')], [('The', 'DT'), ('weather', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('cold', 'VB'), ('today', 'NN'), ('.', '.')]]\n",
      "\n",
      "Synonyms and Antonyms:\n",
      "Word: writing, Synonyms: ['writing.n.01', 'writing.n.02', 'writing.n.03', 'writing.n.04', 'writing.n.05', 'write.v.01', 'write.v.02', 'publish.v.03', 'write.v.04', 'write.v.05', 'compose.v.02', 'write.v.07', 'write.v.08', 'spell.v.03', 'write.v.10'], Antonyms: []\n",
      "Word: skill, Synonyms: ['skill.n.01', 'skill.n.02'], Antonyms: []\n",
      "Word: weather, Synonyms: ['weather.n.01', 'weather.v.01', 'weather.v.02', 'weather.v.03', 'weather.v.04', 'upwind.s.01'], Antonyms: []\n",
      "Word: today, Synonyms: ['today.n.01', 'today.n.02', 'nowadays.r.01', 'today.r.02'], Antonyms: []\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def analyze_paragraph(paragraph):\n",
    "    # Tokenize the paragraph into sentences and words\n",
    "    sentences = sent_tokenize(paragraph)\n",
    "    words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Part-of-speech tagging\n",
    "    pos_tags = [pos_tag(word) for word in words]\n",
    "\n",
    "    # WordNet analysis (synonyms and antonyms)\n",
    "    synonyms_antonyms = []\n",
    "    for sentence in words:\n",
    "        for word, tag in pos_tag(sentence):\n",
    "            if tag.startswith('N'):\n",
    "                synsets = wordnet.synsets(word)\n",
    "                synonyms = [syn.name() for syn in synsets]\n",
    "                antonyms = [antonym.name() for syn in synsets for antonym in syn.lemmas()[0].antonyms()]\n",
    "                synonyms_antonyms.append((word, synonyms, antonyms))\n",
    "\n",
    "    return sentences, pos_tags, synonyms_antonyms\n",
    "\n",
    "# Example paragraph with intentional grammar mistakes\n",
    "input_paragraph = \"He do not likes to go outside. Her writing skill are good, but she could of improved it. The weather is to cold today.\"\n",
    "\n",
    "sentences, pos_tags, synonyms_antonyms = analyze_paragraph(input_paragraph)\n",
    "\n",
    "print(\"Original Paragraph:\")\n",
    "print(input_paragraph)\n",
    "print(\"\\nTokenized Sentences:\")\n",
    "print(sentences)\n",
    "print(\"\\nPart-of-Speech Tags:\")\n",
    "print(pos_tags)\n",
    "print(\"\\nSynonyms and Antonyms:\")\n",
    "for entry in synonyms_antonyms:\n",
    "    word, synonyms, antonyms = entry\n",
    "    print(f\"Word: {word}, Synonyms: {synonyms}, Antonyms: {antonyms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph:\n",
      "He do not likes to go outside. Her writing skill are good, but she could of improved it. The weather is to cold today.\n",
      "\n",
      "Corrected Paragraph:\n",
      "He make not wish to travel outside . Her writing skill be good , but she could of better it . The weather be to cold today .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "def correct_paragraph(paragraph):\n",
    "    sentences = sent_tokenize(paragraph)\n",
    "    corrected_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tags = pos_tag(words)\n",
    "\n",
    "        # Correct errors in the sentence\n",
    "        corrected_words = []\n",
    "        for word, tag in pos_tags:\n",
    "            # Correct nouns\n",
    "            if tag.startswith('N'):\n",
    "                synsets = wordnet.synsets(word)\n",
    "                if synsets:\n",
    "                    corrected_word = synsets[0].lemmas()[0].name()\n",
    "                else:\n",
    "                    corrected_word = word\n",
    "            # Correct verbs\n",
    "            elif tag.startswith('V'):\n",
    "                synsets = wordnet.synsets(word, pos=wordnet.VERB)\n",
    "                if synsets:\n",
    "                    corrected_word = synsets[0].lemmas()[0].name()\n",
    "                else:\n",
    "                    corrected_word = word\n",
    "            # Default correction\n",
    "            else:\n",
    "                corrected_word = word\n",
    "\n",
    "            corrected_words.append(corrected_word)\n",
    "\n",
    "        corrected_sentence = ' '.join(corrected_words)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "\n",
    "    return ' '.join(corrected_sentences)\n",
    "\n",
    "# Example paragraph with intentional grammar mistakes\n",
    "input_paragraph = \"He do not likes to go outside. Her writing skill are good, but she could of improved it. The weather is to cold today.\"\n",
    "\n",
    "corrected_paragraph = correct_paragraph(input_paragraph)\n",
    "\n",
    "print(\"Original Paragraph:\")\n",
    "print(input_paragraph)\n",
    "print(\"\\nCorrected Paragraph:\")\n",
    "print(corrected_paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Her writing skill good'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"her writing skill good\"\n",
    "# is_bad_rule = lambda rule: rule.message == 'Possible spelling mistake found.' and len(rule.replacements) and rule.replacements[0][0].isupper()\n",
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "matches = tool.check(s)\n",
    "# matches = [rule for rule in matches if not is_bad_rule(rule)]\n",
    "language_tool_python.utils.correct(s, matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "gf = Gramformer(models=3, use_gpu=True)\n",
    "gf.correct('My camera battery a dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5405, 0.4995, 0.1336],\n",
      "        [0.9858, 0.8994, 0.7294],\n",
      "        [0.4439, 0.6270, 0.7266],\n",
      "        [0.6470, 0.9489, 0.5710],\n",
      "        [0.2332, 0.4475, 0.1478]])\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import TTSettings\n",
    "from happytransformer import HappyTextToText\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/05/2024 21:08:24 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "happy_tt = HappyTextToText(\"T5\",  \"prithivida/grammar_error_correcter_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"gec: \" + \"her writing skill good.but idnai is good cintry ALL indian s are my brothwer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = TTSettings(do_sample=True, top_k=10, temperature=0.5,  min_length=1, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/05/2024 21:08:25 - INFO - happytransformer.happy_transformer -   Moving model to cuda:0\n",
      "01/05/2024 21:08:26 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her writing skills good.but idnai is good cintry. ALL indians are my brothwer.\n"
     ]
    }
   ],
   "source": [
    "result = happy_tt.generate_text(text, args=settings)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
